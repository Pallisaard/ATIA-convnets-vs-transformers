{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the dataset and analyse whether there are any images with two or more labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_labels = pd.read_csv(\"datasets/isic_2019/ISIC_2019_Training_GroundTruth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any images with two labels? False\n"
     ]
    }
   ],
   "source": [
    "isic_label_values = isic_labels.iloc[:, 1:].values\n",
    "any_double_labels = np.any(np.sum(isic_label_values, axis=1) > 1)\n",
    "print(f\"Are there any images with two labels? {any_double_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all images ahve unique labels. Now let's take a look at formating the labels correctly for each image as well as take a look at the distribution of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25326</th>\n",
       "      <td>ISIC_0073247</td>\n",
       "      <td>BCC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25327</th>\n",
       "      <td>ISIC_0073248</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25328</th>\n",
       "      <td>ISIC_0073249</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>ISIC_0073251</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25330</th>\n",
       "      <td>ISIC_0073254</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image label_name  label\n",
       "0      ISIC_0000000         NV      1\n",
       "1      ISIC_0000001         NV      1\n",
       "2      ISIC_0000002        MEL      0\n",
       "3      ISIC_0000003         NV      1\n",
       "4      ISIC_0000004        MEL      0\n",
       "...             ...        ...    ...\n",
       "25326  ISIC_0073247        BCC      2\n",
       "25327  ISIC_0073248        BKL      4\n",
       "25328  ISIC_0073249        MEL      0\n",
       "25329  ISIC_0073251         NV      1\n",
       "25330  ISIC_0073254        BKL      4\n",
       "\n",
       "[25331 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names = isic_labels.iloc[:, 0]\n",
    "image_labels = isic_labels.iloc[:, 1:].idxmax(axis=1)\n",
    "isic_label_info = pd.concat([image_names, image_labels], axis=1).rename(columns={0: \"label_name\"})\n",
    "isic_label_info[\"label\"] = isic_label_info[\"label_name\"].map({\"MEL\": 0, \"NV\": 1, \"BCC\": 2, \"AK\": 3, \"BKL\": 4, \"DF\": 5, \"VASC\": 6, \"SCC\": 7, \"UNK\": 8})\n",
    "isic_label_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_name\n",
       "label            \n",
       "0            4522\n",
       "1           12875\n",
       "2            3323\n",
       "3             867\n",
       "4            2624\n",
       "5             239\n",
       "6             253\n",
       "7             628"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = isic_label_info.drop(columns=[\"image\"]).groupby([\"label\"]).count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty bad distribution. WE can solve this by first limiting label 0 and 1 to 3000 images each and then sample randomly from each class with a weighted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the first 3000 examples of label 1 (NV) from the dataset isic_label_info\n",
    "is_label_1 = isic_label_info[isic_label_info[\"label\"] == 1]\n",
    "is_not_label_1 = isic_label_info[isic_label_info[\"label\"] != 1]\n",
    "random_label_1_indices = np.random.randint(0, len(is_label_1), 3000)\n",
    "isic_label_info_tmp = pd.concat([is_not_label_1, is_label_1.iloc[random_label_1_indices, :]])\n",
    "\n",
    "# keep only the first 3000 examples of label 0 (MEL) from the dataset isic_label_info\n",
    "is_label_0 = isic_label_info_tmp[isic_label_info_tmp[\"label\"] == 0]\n",
    "is_not_label_0 = isic_label_info_tmp[isic_label_info_tmp[\"label\"] != 0]\n",
    "random_label_0_indices = np.random.randint(0, len(is_label_0), 3000)\n",
    "isic_label_info_balanced = pd.concat([is_not_label_0, is_label_0.iloc[random_label_0_indices, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_name\n",
       "label            \n",
       "0            3000\n",
       "1            3000\n",
       "2            3323\n",
       "3             867\n",
       "4            2624\n",
       "5             239\n",
       "6             253\n",
       "7             628"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_label_info_balanced.drop(columns=[\"image\"]).groupby([\"label\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, now lets create a vector of probabilities for each individual image. This can be used with the WeightedRandomSampler in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02725287, 0.02725287, 0.02460386, 0.0943006 , 0.03115801,\n",
       "       0.34208628, 0.32315661, 0.13018889])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_label_counts = isic_label_info_balanced.drop(columns=[\"image\"]).groupby([\"label\"]).count()[\"label_name\"].values\n",
    "highest_label_count = np.repeat(np.max(balanced_label_counts), len(balanced_label_counts))\n",
    "sample_ratios = highest_label_count / balanced_label_counts\n",
    "sample_probabilities = sample_ratios / np.sum(sample_ratios)\n",
    "sample_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine this with the info table to creat the final metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "      <th>sample_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>ISIC_0010491</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>ISIC_0012086_downsampled</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>ISIC_0012090_downsampled</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>ISIC_0012103_downsampled</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>ISIC_0012117_downsampled</td>\n",
       "      <td>BKL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>ISIC_0054747</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15303</th>\n",
       "      <td>ISIC_0057307</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21846</th>\n",
       "      <td>ISIC_0067747</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15755</th>\n",
       "      <td>ISIC_0058059</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>ISIC_0029570</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13934 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image label_name  label  sample_prob\n",
       "1008               ISIC_0010491        BKL      4     0.031158\n",
       "1234   ISIC_0012086_downsampled        BKL      4     0.031158\n",
       "1236   ISIC_0012090_downsampled        BKL      4     0.031158\n",
       "1243   ISIC_0012103_downsampled        BKL      4     0.031158\n",
       "1249   ISIC_0012117_downsampled        BKL      4     0.031158\n",
       "...                         ...        ...    ...          ...\n",
       "13713              ISIC_0054747        MEL      0     0.027253\n",
       "15303              ISIC_0057307        MEL      0     0.027253\n",
       "21846              ISIC_0067747        MEL      0     0.027253\n",
       "15755              ISIC_0058059        MEL      0     0.027253\n",
       "8167               ISIC_0029570        MEL      0     0.027253\n",
       "\n",
       "[13934 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_meta_table = isic_label_info_balanced.copy()\n",
    "isic_meta_table[\"sample_prob\"] = sample_probabilities[isic_meta_table[\"label\"].values]\n",
    "isic_meta_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets create a function that will take the original meta data table and create our preferred one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_isic_ground_truth_table(filepath, save_result=True, save_path=None):\n",
    "    isic_labels = pd.read_csv(filepath)\n",
    "    \n",
    "    # Format the data into a table having the image name, the label name and the label\n",
    "    image_names = isic_labels.iloc[:, 0]\n",
    "    image_labels = isic_labels.iloc[:, 1:].idxmax(axis=1)\n",
    "    isic_label_info = pd.concat([image_names, image_labels], axis=1).rename(columns={0: \"label_name\"})\n",
    "    isic_label_info[\"label\"] = isic_label_info[\"label_name\"].map(\n",
    "        {\"MEL\": 0, \"NV\": 1, \"BCC\": 2, \"AK\": 3, \"BKL\": 4, \"DF\": 5, \"VASC\": 6, \"SCC\": 7, \"UNK\": 8}\n",
    "    ).astype(np.int32)\n",
    "    isic_label_info\n",
    "    \n",
    "    # keep only the first 3000 examples of label 1 (NV) from the dataset isic_label_info\n",
    "    is_label_1 = isic_label_info[isic_label_info[\"label\"] == 1]\n",
    "    is_not_label_1 = isic_label_info[isic_label_info[\"label\"] != 1]\n",
    "    random_label_1_indices = np.random.randint(0, len(is_label_1), 3000)\n",
    "    isic_label_info_tmp = pd.concat([is_not_label_1, is_label_1.iloc[random_label_1_indices, :]])\n",
    "\n",
    "    # keep only the first 3000 examples of label 0 (MEL) from the dataset isic_label_info\n",
    "    is_label_0 = isic_label_info_tmp[isic_label_info_tmp[\"label\"] == 0]\n",
    "    is_not_label_0 = isic_label_info_tmp[isic_label_info_tmp[\"label\"] != 0]\n",
    "    random_label_0_indices = np.random.randint(0, len(is_label_0), 3000)\n",
    "    isic_label_info_balanced = pd.concat([is_not_label_0, is_label_0.iloc[random_label_0_indices, :]])\n",
    "    \n",
    "    # Create sample probabilities\n",
    "    balanced_label_counts = isic_label_info_balanced.drop(columns=[\"image\"]).groupby([\"label\"]).count()[\"label_name\"].values\n",
    "    highest_label_count = np.repeat(np.max(balanced_label_counts), len(balanced_label_counts))\n",
    "    sample_ratios = highest_label_count / balanced_label_counts\n",
    "    sample_probabilities = sample_ratios / np.sum(sample_ratios)\n",
    "    \n",
    "    isic_gt_table = isic_label_info_balanced.copy()\n",
    "    isic_gt_table[\"sample_prob\"] = sample_probabilities[isic_gt_table[\"label\"].values]\n",
    "    \n",
    "    if save_result and save_path is not None:\n",
    "        isic_gt_table.to_csv(save_path, index=False)\n",
    "    \n",
    "    return isic_gt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13934"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_gt = create_isic_ground_truth_table(\"datasets/isic_2019/ISIC_2019_Training_GroundTruth.csv\", save_path=\"datasets/isic_2019/isic_2019_ground_truth.csv\")\n",
    "len(isic_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of ISIC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of example image: (1022, 767)\n"
     ]
    }
   ],
   "source": [
    "example_image = PIL.Image.open(\"datasets/isic_2019/images/ISIC_2019_Training_Input/ISIC_0000000.jpg\")\n",
    "example_image = example_image.convert(\"RGB\")\n",
    "print(f\"size of example image: {example_image.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see remarkably larger images than we did with CIFAR. Lets now discuss how to appropriately handle these images. We suggest resizing such that the shortest side is 256 pixels, and afterwards to a random crop as suggested in BiT. This will allow us to use a pretrained model with a 224x224 input size. We will also use the same normalization as before.\n",
    "\n",
    "We resize such that the shortest side is 256 pixels and then take a random crop of size 224x224 because we want to keep the aspect ratio of the image.\n",
    "\n",
    "The discussion of this should mainly focus on center crop vs random crop. While we assume that all images are adequately centered, making a centered crop a good option. One could also argue that a random crop introduces more varied data and lets our models learn more robust features. We will use a random crop for now, but may change to center crop later. If we change, it will be noted below.\n",
    "\n",
    "In terms of output sizes, since both models can handle 224x224 images and the images in the dataset are of high resolution, we will scale down to 224x224 for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cifar10_feature_extractor(image_size=(224, 224)):\n",
    "#     return T.Compose([\n",
    "#         T.PILToTensor(),\n",
    "#         T.Resize(image_size, T.InterpolationMode.BILINEAR, antialias=False),\n",
    "#         T.ConvertImageDtype(torch.float32),\n",
    "#         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "im = example_image\n",
    "im_width, im_height = im.size\n",
    "im_smallest_size = np.min(im.size)\n",
    "resize_ratio = 256 / im_smallest_size\n",
    "\n",
    "resize_width = int(im_width * resize_ratio)\n",
    "resize_height = int(im_height * resize_ratio)\n",
    "\n",
    "isic_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(256, T.InterpolationMode.BILINEAR, antialias=False),\n",
    "    T.RandomCrop((224, 224)),\n",
    "    T.ConvertImageDtype(torch.float32),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_transform(example_image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can define a feature extractor for the ISIC 2019 dataset as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isic_2019_feature_extractor(image_size=224):\n",
    "    return T.Compose([\n",
    "        T.PILToTensor(),\n",
    "        T.Resize(image_size, T.InterpolationMode.BILINEAR, antialias=False),\n",
    "        T.RandomCrop((224, 224)),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ISIC 2019 dataset using the python file\n",
    "\n",
    "We have now used this to create a python file with the dataset and the feature extractor build in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isic_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4980, 0.4863, 0.4784,  ..., 0.5020, 0.4980, 0.4980],\n",
       "          [0.4824, 0.4784, 0.4784,  ..., 0.5020, 0.4980, 0.4980],\n",
       "          [0.4824, 0.4824, 0.4863,  ..., 0.5020, 0.5020, 0.4980],\n",
       "          ...,\n",
       "          [0.4706, 0.4784, 0.4824,  ..., 0.5059, 0.5059, 0.5059],\n",
       "          [0.4706, 0.4745, 0.4824,  ..., 0.5137, 0.5137, 0.5137],\n",
       "          [0.4706, 0.4784, 0.4863,  ..., 0.5137, 0.5137, 0.5137]],\n",
       " \n",
       "         [[0.4549, 0.4431, 0.4353,  ..., 0.4980, 0.4941, 0.4941],\n",
       "          [0.4431, 0.4353, 0.4353,  ..., 0.4980, 0.4941, 0.4941],\n",
       "          [0.4431, 0.4431, 0.4431,  ..., 0.4980, 0.4980, 0.4941],\n",
       "          ...,\n",
       "          [0.4392, 0.4471, 0.4510,  ..., 0.4863, 0.4863, 0.4863],\n",
       "          [0.4392, 0.4431, 0.4510,  ..., 0.4941, 0.4941, 0.4941],\n",
       "          [0.4392, 0.4471, 0.4549,  ..., 0.4941, 0.4941, 0.4941]],\n",
       " \n",
       "         [[0.4471, 0.4353, 0.4275,  ..., 0.4902, 0.4863, 0.4863],\n",
       "          [0.4353, 0.4275, 0.4275,  ..., 0.4902, 0.4863, 0.4863],\n",
       "          [0.4353, 0.4353, 0.4353,  ..., 0.4902, 0.4902, 0.4863],\n",
       "          ...,\n",
       "          [0.4275, 0.4353, 0.4392,  ..., 0.4627, 0.4627, 0.4627],\n",
       "          [0.4275, 0.4314, 0.4392,  ..., 0.4706, 0.4706, 0.4706],\n",
       "          [0.4275, 0.4353, 0.4431,  ..., 0.4706, 0.4706, 0.4706]]]),\n",
       " 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_2019_dataset = isic_2019.ISIC2019Dataset(\n",
    "    root=\"~/datasets/isic_2019\"\n",
    ")\n",
    "isic_2019_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(\"datasets/isic_2019old/images/ISIC_2019_Training_Input/ISIC_0000000.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a2807571ceb5298b2f1983d1350812d9420f551039ce5a6ed3c5736a180364b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
