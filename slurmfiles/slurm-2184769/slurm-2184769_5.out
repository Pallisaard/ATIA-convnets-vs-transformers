0,1,2,3
Running convnext training on 0,1,2,3
11.6
True
4
creating checkpoint.
initializing ConvNext model.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
11.6
True
4
creating checkpoint.
initializing ConvNext model.
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
11.6
True
4
creating checkpoint.
initializing ConvNext model.
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
11.6
True
4
creating checkpoint.
initializing ConvNext model.
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

preparing ISIC 2019 dataset.
creating data loaders.
fitting model.
preparing ISIC 2019 dataset.
creating data loaders.
fitting model.
preparing ISIC 2019 dataset.
creating data loaders.
fitting model.
preparing ISIC 2019 dataset.
creating data loaders.
fitting model.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name    | Type             | Params
---------------------------------------------
0 | loss_fn | CrossEntropyLoss | 0     
1 | model   | ConvNeXt         | 87.6 M
---------------------------------------------
87.6 M    Trainable params
0         Non-trainable params
87.6 M    Total params
350.307   Total estimated model params size (MB)
Traceback (most recent call last):
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 648, in _call_and_handle_interrupt
    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 93, in launch
    return function(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/home/dwp992/home/projects/ATIA-convnets-vs-transformers/models/ConvNext.py", line 61, in validation_step
    loss = self.loss_fn(outputs, labels)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1164, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Double'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dwp992/home/projects/ATIA-convnets-vs-transformers/main.py", line 96, in <module>
    main()
  File "/home/dwp992/home/projects/ATIA-convnets-vs-transformers/main.py", line 90, in main
    trainer.fit(model,
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 662, in _call_and_handle_interrupt
    self.strategy.reconciliate_processes(traceback.format_exc())
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 454, in reconciliate_processes
    raise DeadlockDetectedException(f"DeadLock detected from rank: {self.global_rank} \n {trace}")
pytorch_lightning.utilities.exceptions.DeadlockDetectedException: DeadLock detected from rank: 0 
 Traceback (most recent call last):
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 648, in _call_and_handle_interrupt
    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 93, in launch
    return function(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/home/dwp992/home/projects/ATIA-convnets-vs-transformers/models/ConvNext.py", line 61, in validation_step
    loss = self.loss_fn(outputs, labels)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1164, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/dwp992/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Double'

